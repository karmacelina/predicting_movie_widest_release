{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 'caffeinate' on MacOSX to prevent the system from sleeping\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "if 'darwin' in sys.platform:\n",
    "    print('Running \\'caffeinate\\' on MacOSX to prevent the system from sleeping')\n",
    "    subprocess.Popen('caffeinate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "import string\n",
    "from bs4 import BeautifulSoup  \n",
    "import logging  \n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "import dateutil.parser\n",
    "import time\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get movie urls from boxofficemojo.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_movies():  \n",
    "    \"\"\" returns all the movie urls from boxofficemojo.com in a list\"\"\"\n",
    "\n",
    "    # Alphabet loop for how movies are indexed including\n",
    "    # movies that start with a special character or number\n",
    "    index = [\"NUM\"] + list(string.ascii_uppercase)\n",
    "\n",
    "    # List of movie urls\n",
    "    movies_list = []\n",
    "\n",
    "    # Loop through the pages for each letter\n",
    "    for letter in index:\n",
    "\n",
    "        # Loop through the pages within each letter\n",
    "        for num in range(1, 20):\n",
    "            url = (\"http://www.boxofficemojo.com/movies/alphabetical.htm?\"\n",
    "                   \"letter=\" + letter + \"&page=\" + str(num))\n",
    "            try:\n",
    "                response = requests.get(url)\n",
    "                page = response.text\n",
    "                soup = BeautifulSoup(page, \"lxml\")\n",
    "                rows = soup.find(id=\"body\").find(\"table\").find(\"table\").find_all(\n",
    "                    \"table\")[1].find_all(\"tr\")\n",
    "\n",
    "                # skip index row\n",
    "                if len(rows) > 1:\n",
    "                    counter = 1\n",
    "                    for row in rows:\n",
    "                        # skip index row\n",
    "                        if counter > 1:\n",
    "                            link = row.td.font.a['href']\n",
    "                            # don't add duplicates\n",
    "                            if link not in movies_list:\n",
    "                                movies_list.append(link)\n",
    "\n",
    "                        counter += 1\n",
    "            except (Exception, e):\n",
    "                logging.exception(e)\n",
    "\n",
    "    return movies_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To get the url of the movies, call the function defined above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_movies = get_all_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_movies_subset = all_movies[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(len(movie_chunks))\n",
    "#print(len(all_movies))\n",
    "#n = list(range(len(all_movies)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#L = int(len(all_movies)/80)\n",
    "#intervals = n[::L]\n",
    "#intervals.append(len(all_movies)-1)\n",
    "#print (intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in intervals:\n",
    "#    for movie in all_movies[intervals[i]:intervals[i+1]]:\n",
    "#        print(movie)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#L = int(len(all_movies)/40)\n",
    "#L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#url = 'http://www.boxofficemojo.com/movies/?id=addamsfamily.htm'\n",
    "#url = 'http://www.boxofficemojo.com/movies/?id=casablanca.htm'\n",
    "#response = requests.get(url)\n",
    "#page = response.text\n",
    "#soup = BeautifulSoup(page, \"lxml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define certain useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_movie_value(soup, field_name):\n",
    "    '''Grab a value from boxofficemojo HTML\n",
    "    \n",
    "    Takes a string attribute of a movie on the page and\n",
    "    returns the string in the next sibling object\n",
    "    (the value for that attribute)\n",
    "    or None if nothing is found.\n",
    "    '''\n",
    "    obj = soup.find(text=re.compile(field_name))\n",
    "    if not obj: \n",
    "        return None\n",
    "    # this works for most of the values\n",
    "    next_sibling = obj.findNextSibling()\n",
    "    if next_sibling:\n",
    "        return next_sibling.text # RETURN TEXT OF NEXT SIBLING\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_movie_value_next(soup, field_name):\n",
    "    '''Grab a value from boxofficemojo HTML\n",
    "    \n",
    "    Takes a string attribute of a movie on the page and\n",
    "    returns the string in the next sibling object\n",
    "    (the value for that attribute)\n",
    "    or None if nothing is found.\n",
    "    '''\n",
    "    obj = soup.find(text=re.compile(field_name))\n",
    "    if not obj: \n",
    "        return None\n",
    "    # this works for most of the values\n",
    "    next_sibling = obj.findNextSibling()\n",
    "    if next_sibling:\n",
    "        return next_sibling.text # RETURN TEXT OF NEXT SIBLING\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def get_movie_value_next_next(soup, field_name):\n",
    "    '''Grab a value from boxofficemojo HTML\n",
    "    \n",
    "    Takes a string attribute of a movie on the page and\n",
    "    returns the string in the next sibling object\n",
    "    (the value for that attribute)\n",
    "    or None if nothing is found.\n",
    "    '''\n",
    "    obj = soup.find(text=re.compile(field_name))\n",
    "    \n",
    "    if obj:\n",
    "        return obj.next.next.text\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def money_to_int(moneystring):\n",
    "    moneystring = moneystring.replace('$', '').replace(',', '')\n",
    "    return int(moneystring)\n",
    "\n",
    "\n",
    "#fix this here. ARGH!\n",
    "#def money_to_int_2(moneystring):\n",
    "#    if moneystring != 'N/A':\n",
    "#        moneystring = moneystring.replace('$', '').replace('.','').replace(',','').replace(' million', '000000')\n",
    "#        return int(moneystring)\n",
    "\n",
    "#def money_to_int_2(moneystring):\n",
    "#    if moneystring != 'N/A':\n",
    "#        moneystring = moneystring.replace('$','').replace(',','')\n",
    "#        if 'million' in moneystring:\n",
    "#            moneystring.replace('million','')\n",
    "#            return float(moneystring)*1000000\n",
    "#        else:\n",
    "#            return float(moneystring)\n",
    "        \n",
    "def money_to_int_2(string):\n",
    "    if string is not None:\n",
    "        i = string.replace('$','').replace(',','').replace(' ','')\n",
    "        if \"million\" in i:\n",
    "            i = i.replace('million','')\n",
    "            i = float(i) * 1000000\n",
    "            i = int(i)\n",
    "        return i\n",
    "    else:\n",
    "       return np.nan\n",
    "\n",
    "def runtime_to_minutes(runtimestring):\n",
    "    runtime = runtimestring.split()\n",
    "    try:\n",
    "        minutes = int(runtime[0])*60 + int(runtime[2])\n",
    "        return minutes\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def strip_and_return_int(s):\n",
    "    t = s.replace('$', '').replace(',','')\n",
    "    t = int(t)\n",
    "    return t\n",
    "\n",
    "def to_date(datestring):\n",
    "    date = dateutil.parser.parse(datestring)\n",
    "    return date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions to get movie information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def movie_title(soup):        \n",
    "    #try:\n",
    "    title_string = soup.find('title').text\n",
    "    title = title_string.split('(')[0].strip()\n",
    "    #except:\n",
    "        #title = float('NaN')\n",
    "        \n",
    "    return title \n",
    "    \n",
    "def movie_producers(soup):\n",
    "    try:\n",
    "        producer = get_movie_value_next(soup, 'Producer')\n",
    "        producers = re.sub('([a-z()])([A-Z])', '\\g<1>, \\g<2>', producer).split(\",\") \n",
    "    except TypeError:\n",
    "        producers = float('NaN')\n",
    "    except AttributeError:\n",
    "        producers = float('NaN')\n",
    "        \n",
    "    return producers\n",
    "        \n",
    "def movie_directors(soup):\n",
    "    try:\n",
    "        director = get_movie_value_next(soup,'Director')\n",
    "        director = re.sub('([a-z()])([A-Z])', '\\g<1>, \\g<2>', director).split(\",\") \n",
    "    except TypeError:\n",
    "        director = float('NaN')\n",
    "    \n",
    "    return director\n",
    "    \n",
    "#def movie_actors(soup):\n",
    "#    try:\n",
    "#        actor = get_movie_value_next(soup,'Actor')\n",
    "#        v = re.sub('([a-z()])([A-Z])', '\\g<1>, \\g<2>', actor)\n",
    "#        actors = re.sub('[(*\\']','', v)\n",
    "#        actors = actors.split(\",\") \n",
    "#    except TypeError:\n",
    "#        actors = float('NaN')\n",
    "#\n",
    "#    return actors\n",
    "\n",
    "#def movie_actors(soup):\n",
    "#    try:\n",
    "#        actor = get_movie_value_next(soup,'Actor')\n",
    "#        if '*' in actor:\n",
    "#            actors =  actor.split('*')\n",
    "#        else:\n",
    "#            v = re.sub('([a-z()])([A-Z])', '\\g<1>, \\g<2>', actor)\n",
    "#            actors = re.sub('[(*\\']','', v)\n",
    "#            actors = actors.split(\",\") \n",
    "#    except TypeError:\n",
    "#        actors = float('NaN')\n",
    "#    return actors\n",
    "\n",
    "def movie_actors(soup): # still doesn't deal well with McPeople\n",
    "    try:\n",
    "        actor = get_movie_value_next_next(soup,'Actor') # try get_movie_value_next if it doesnt work \n",
    "        v = re.sub('([a-z()])([A-Z])', '\\g<1>, \\g<2>', actor)\n",
    "        v = v.replace('(, Voice)','')\n",
    "        if \"*\" in v:\n",
    "            actors = v.split('*')\n",
    "        else:\n",
    "            actors = re.sub('[(*\\']','', v)\n",
    "            actors = actors.split(\",\")\n",
    "\n",
    "    except TypeError:\n",
    "        actors = float('NaN')\n",
    "    return actors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def movie_genre(soup):\n",
    "    try:\n",
    "        genre = get_movie_value(soup, 'Genre[^a-z]')\n",
    "    except:\n",
    "        genre = float('NaN')\n",
    "    return genre\n",
    "\n",
    "def movie_rating(soup):\n",
    "    try:\n",
    "        rating = get_movie_value(soup,'MPAA Rating')\n",
    "    except:\n",
    "        rating = float('NaN')\n",
    "    return rating\n",
    "\n",
    "#def release_date(soup):\n",
    "#    try:\n",
    "#        raw_release_date = get_movie_value(soup,'Release Date')\n",
    "#        if raw_release_date != 'TBD' and raw_release_date != 'N/A' and raw_release_date[0].isnumeric() :\n",
    "#            release_date = to_date(raw_release_date)\n",
    "#        else:\n",
    "#            release_date = float('NaN')\n",
    "#    except AttributeError:\n",
    "#        release_date = float('NaN')\n",
    "#    \n",
    "#    return release_date\n",
    "\n",
    "def release_date(soup):\n",
    "    try:\n",
    "        raw_release_date = get_movie_value(soup,'Release Date')\n",
    "        if raw_release_date != 'TBD' and raw_release_date != 'N/A' and raw_release_date.split()[0] != 'Spring' and raw_release_date.split()[0] != 'Summer' and raw_release_date.split()[0] != 'Fall' and raw_release_date.split()[0] != 'Winter' :\n",
    "            release_date = to_date(raw_release_date)\n",
    "        else:\n",
    "            release_date = float('NaN')\n",
    "    except AttributeError:\n",
    "        release_date = float('NaN')\n",
    "    return release_date\n",
    "    \n",
    "def domestic_gross(soup):\n",
    "    \n",
    "    try:\n",
    "        raw_domestic_total_gross = get_movie_value(soup,'Domestic Total')\n",
    "        domestic_total_gross = money_to_int(raw_domestic_total_gross)\n",
    "    except AttributeError:\n",
    "        domestic_total_gross = float('NaN')\n",
    "    \n",
    "    return domestic_total_gross\n",
    "    \n",
    "def opening_weekend_gross(soup):\n",
    "    \n",
    "    try:\n",
    "        opening_weekend_gross = get_movie_value_next(soup,'Opening Weekend')\n",
    "        opening_weekend_gross = money_to_int(opening_weekend_gross)\n",
    "    except AttributeError:\n",
    "        opening_weekend_gross = float('NaN')\n",
    "    return opening_weekend_gross\n",
    "    \n",
    "def production_budget(soup):\n",
    "    try:\n",
    "        production_budget = get_movie_value(soup, 'Production Budget')\n",
    "        production_budget = money_to_int_2(production_budget)\n",
    "    except AttributeError:\n",
    "        production_budget = float('NaN')\n",
    "    return production_budget\n",
    "    \n",
    "def runtime(soup):\n",
    "    try:\n",
    "        raw_runtime = get_movie_value(soup,'Runtime')\n",
    "        runtime = runtime_to_minutes(raw_runtime)\n",
    "    except AttributeError:\n",
    "        runtime = float('NaN')\n",
    "    return runtime\n",
    "    \n",
    "def widest_release(soup):\n",
    "    try:\n",
    "        widest_release = get_movie_value_next_next(soup, 'Widest')\n",
    "        widest_release = strip_and_return_int(widest_release.split()[0])\n",
    "    except AttributeError:\n",
    "        widest_release = float('NaN')\n",
    "    return widest_release\n",
    "\n",
    "def distributor(soup):\n",
    "    try:\n",
    "        if str(soup.find(id='body')) != 'None':\n",
    "            distributor = soup.find(id=\"body\").find(text=re.compile(\"Distributor\"))\n",
    "            if str(distributor) != 'None':\n",
    "                distributor = distributor.findNextSibling().text\n",
    "                return distributor\n",
    "    except LookupError:\n",
    "        distributor = float('NaN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#movie_blocks = list(range(0, len(all_movies)-1, int(len(all_movies)/40)))\n",
    "#movie_blocks.append(len(all_movies)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#from traceback import format_exc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOVIE SCRAPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def movie_scraper(all_movies):    \n",
    "    movie_blocks = list(range(0, len(all_movies)-1, int(len(all_movies)/30)))\n",
    "    movie_blocks.append(len(all_movies)-1) \n",
    "            \n",
    "    print(\"The length of urls_chunks, minus one is %s\" % str(len(movie_blocks)-1))\n",
    "    \n",
    "    movie_data_list = OrderedDict()\n",
    "    count = 0 \n",
    "    try:\n",
    "        for block_index in range(len(movie_blocks) - 1):\n",
    "                    \n",
    "            print (\"URL chunk ... %s of %s in 10 seconds ... \\n\" % (str(block_index), str(len(movie_blocks) - 1)))\n",
    "            \n",
    "            time.sleep(10)\n",
    "            \n",
    "            print (\"Fetching URLs in movie_list location: %s to %s \\n\" % (movie_blocks[block_index], movie_blocks[block_index + 1]))\n",
    "            for movie in all_movies[movie_blocks[block_index]:movie_blocks[block_index + 1]]:\n",
    "                count +=1\n",
    "                url = \"http://www.boxofficemojo.com/\" + movie\n",
    "                response = requests.get(url)\n",
    "                time.sleep(0.1)\n",
    "                page = response.text\n",
    "                soup = BeautifulSoup(page, \"lxml\")\n",
    "                print(count,movie)\n",
    "                movie_data_list[movie_title(soup)] = [movie, movie_genre(soup), release_date(soup), \n",
    "                                                        distributor(soup), runtime(soup), \n",
    "                                                        movie_rating(soup), production_budget(soup), \n",
    "                                                        domestic_gross(soup), movie_actors(soup), \n",
    "                                                        opening_weekend_gross(soup), widest_release(soup),\n",
    "                                                        movie_producers(soup), movie_directors(soup) ]\n",
    "                        \n",
    "                \n",
    "                \n",
    "                #try:\n",
    "                #    time.sleep(0.2)\n",
    "                #    response = requests.get(url)\n",
    "                #    page = response.text\n",
    "                #    #print(str(re.search('\\w+(?=\\.htm)', url).group()))\n",
    "                #    soupObjects[str(re.search('\\w+(?=\\.htm)',url).group())] = BeautifulSoup(page,'lxml')\n",
    "                #except requests.exceptions.RequestException as e:\n",
    "                #    print(e)\n",
    "                #    sys.exit(1)\n",
    "                #\n",
    "                    \n",
    "            print(\"continuing in 10 seconds ...\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "        pass\n",
    "        #sys.exit(1)\n",
    "            \n",
    "    return movie_data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def scrape_movie_data(movie_list):#, start=0, end=20000):\n",
    "#    \"\"\"returns dictionary of movies and relevant data from boxofficemojo.com:\n",
    "#    genres(as a list), release date, distributor, runtime, MPAA rating,\n",
    "#    budget, gross domestic revenue\n",
    "#    \"\"\"\n",
    "#    movie_data_list = OrderedDict()\n",
    "#    count = 0 \n",
    "#    for movie in movie_list:\n",
    "#        count +=1\n",
    "#        url = \"http://www.boxofficemojo.com/\" + movie\n",
    "#        response = requests.get(url)\n",
    "#        time.sleep(0.1)\n",
    "#        page = response.text\n",
    "#        soup = BeautifulSoup(page, \"lxml\")\n",
    "#        print(count, movie)\n",
    "#        movie_data_list[movie_title(soup)] = [movie, movie_genre(soup), release_date(soup), \n",
    "#                                                distributor(soup), runtime(soup), \n",
    "#                                                movie_rating(soup), production_budget(soup), \n",
    "#                                                domestic_gross(soup), movie_actors(soup), \n",
    "#                                                opening_weekend_gross(soup), widest_release(soup),\n",
    "#                                                movie_producers(soup), movie_directors(soup) ]\n",
    "#                \n",
    "#\n",
    "#    return movie_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of urls_chunks, minus one is 30\n",
      "URL chunk ... 0 of 30 in 10 seconds ... \n",
      "\n",
      "Fetching URLs in movie_list location: 0 to 556 \n",
      "\n",
      "1 /movies/?id=horrorifc.htm\n",
      "2 /movies/?id=9dot99.htm\n",
      "3 /movies/?id=supercapitalist.htm\n",
      "4 /movies/?id=500daysofsummer.htm\n",
      "5 /movies/?id=untitled.htm\n",
      "6 /movies/?id=andjusticeforall.htm\n",
      "7 /movies/?id=1mileabove.htm\n",
      "8 /movies/?id=1plus1.htm\n",
      "9 /movies/?id=1000rupeenote.htm\n",
      "10 /movies/?id=1000times.htm\n",
      "11 /movies/?id=10.htm\n",
      "12 /movies/?id=badrobot2016.htm\n",
      "13 /movies/?id=10daysinamadhouse.htm\n",
      "14 /movies/?id=10itemsorless.htm\n",
      "15 /movies/?id=10questionsforthedalailama.htm\n",
      "16 /movies/?id=10rules.htm\n",
      "17 /movies/?id=10thingsihateaboutyou.htm\n",
      "18 /movies/?id=10tomidnight.htm\n",
      "19 /movies/?id=10years.htm\n",
      "20 /movies/?id=10000bc.htm\n",
      "21 /movies/?id=10000km.htm\n",
      "22 /movies/?id=100bloodyacres.htm\n",
      "23 /movies/?id=100yearoldman.htm\n",
      "24 /movies/?id=1001grams.htm\n",
      "25 /movies/?id=101dalmations.htm\n",
      "26 /movies/?id=101dalmatiansliveaction.htm\n",
      "27 /movies/?id=101dalmatians69.htm\n",
      "28 /movies/?id=101dalmatians79.htm\n",
      "29 /movies/?id=101dalmatians85.htm\n",
      "30 /movies/?id=101dalmatians91.htm\n",
      "31 /movies/?id=101reykjavik.htm\n",
      "32 /movies/?id=102dalmatians.htm\n",
      "33 /movies/?id=10thandwolf.htm\n",
      "34 /movies/?id=11flowers.htm\n",
      "35 /movies/?id=111111.htm\n",
      "36 /movies/?id=11thhour15.htm\n",
      "37 /movies/?id=11thhour.htm\n",
      "38 /movies/?id=12.htm\n",
      "39 /movies/?id=12angrymen.htm\n",
      "40 /movies/?id=twelvemonkeys.htm\n",
      "41 /movies/?id=12oclockboys.htm\n",
      "42 /movies/?id=12rounds.htm\n",
      "43 /movies/?id=twelveyearsaslave.htm\n",
      "44 /movies/?id=121212.htm\n",
      "45 /movies/?id=127hours.htm\n",
      "46 /movies/?id=1208eastofbucharest.htm\n",
      "47 /movies/?id=13assassins.htm\n",
      "48 /movies/?id=13conversationsaboutonething.htm\n",
      "49 /movies/?id=13goingon30.htm\n",
      "50 /movies/?id=13hoursthesecretsoldiersofbenghazi.htm\n",
      "51 /movies/?id=13monthsofsunshine.htm\n",
      "52 /movies/?id=13sins.htm\n",
      "53 /movies/?id=13tzameti.htm\n",
      "54 /movies/?id=13b.htm\n",
      "55 /movies/?id=13thalley.htm\n",
      "56 /movies/?id=13thwarrior.htm\n",
      "57 /movies/?id=14blades.htm\n",
      "58 /movies/?id=1408.htm\n",
      "59 /movies/?id=1492.htm\n",
      "60 /movies/?id=15.htm\n",
      "61 /movies/?id=15fevrier1839.htm\n",
      "62 /movies/?id=15minutes.htm\n",
      "63 /movies/?id=16blocks.htm\n",
      "64 /movies/?id=16daysofglory.htm\n",
      "65 /movies/?id=16yearsofalcohol.htm\n",
      "66 /movies/?id=17again.htm\n",
      "67 /movies/?id=17girls.htm\n",
      "68 /movies/?id=18again.htm\n",
      "69 /movies/?id=18ansapres.htm\n",
      "70 /movies/?id=180south.htm\n",
      "71 /movies/?id=187.htm\n",
      "72 /movies/?id=1900.htm\n",
      "73 /movies/?id=1911.htm\n",
      "74 /movies/?id=1915.htm\n",
      "75 /movies/?id=1920london.htm\n",
      "76 /movies/?id=1941.htm\n",
      "77 /movies/?id=1969.htm\n",
      "78 /movies/?id=1984.htm\n",
      "79 /movies/?id=1995bugsbunnyfilmfestival.htm\n",
      "80 /movies/?id=1998bugsbunnyfilmfestival.htm\n",
      "81 /movies/?id=2autumns.htm\n",
      "82 /movies/?id=2daysinnewyork.htm\n",
      "83 /movies/?id=2daysinparis.htm\n",
      "84 /movies/?id=2daysinthevalley.htm\n",
      "85 /movies/?id=2fast2furious.htm\n",
      "86 /movies/?id=2guns.htm\n",
      "87 /movies/?id=2jacks.htm\n",
      "88 /movies/?id=2states.htm\n",
      "89 /movies/?id=20centimeters.htm\n",
      "90 /movies/?id=20dates.htm\n",
      "91 /movies/?id=20feetfromstardom.htm\n",
      "92 /movies/?id=20millionmilestoearth.htm\n",
      "93 /movies/?id=20onceagain.htm\n",
      "94 /movies/?id=20000daysonearth.htm\n",
      "95 /movies/?id=200cartas.htm\n",
      "96 /movies/?id=200cigarettes.htm\n",
      "97 /movies/?id=2001.htm\n",
      "98 /movies/?id=20012013.htm\n",
      "99 /movies/?id=200101.htm\n",
      "100 /movies/?id=shorts06.htm\n",
      "101 /movies/?id=2006shortfilms.htm\n",
      "102 /movies/?id=2007shortfilms.htm\n",
      "103 /movies/?id=2008oscarshorts.htm\n",
      "104 /movies/?id=2010.htm\n",
      "105 /movies/?id=2010oscarshorts.htm\n",
      "106 /movies/?id=2011oscarshorts.htm\n",
      "107 /movies/?id=2012.htm\n",
      "108 /movies/?id=2012oscarshorts.htm\n",
      "109 /movies/?id=2012timeforchange.htm\n",
      "110 /movies/?id=2013oscar.htm\n",
      "111 /movies/?id=2014oscar.htm\n",
      "112 /movies/?id=2015oscarshorts.htm\n",
      "113 /movies/?id=2016obamasamerica.htm\n",
      "114 /movies/?id=2016oscarnominatedshortfilms.htm\n",
      "115 /movies/?id=2046.htm\n",
      "116 /movies/?id=20thcenturywomen.htm\n",
      "117 /movies/?id=21.htm\n",
      "118 /movies/?id=21andover.htm\n",
      "119 /movies/?id=21grams.htm\n",
      "120 /movies/?id=21jumpstreet.htm\n",
      "121 /movies/?id=22bullets.htm\n",
      "122 /movies/?id=21jumpstreet2.htm\n",
      "123 /movies/?id=22ndtourneeofanimation.htm\n",
      "124 /movies/?id=23blast.htm\n",
      "125 /movies/?id=23rdtourneeofanimation.htm\n",
      "126 /movies/?id=242016.htm\n",
      "127 /movies/?id=24city.htm\n",
      "128 /movies/?id=24hourparty.htm\n",
      "129 /movies/?id=24-hourwoman.htm\n",
      "130 /movies/?id=24thday.htm\n",
      "131 /movies/?id=24thtourneeofanimation.htm\n",
      "132 /movies/?id=25thhour.htm\n",
      "133 /movies/?id=27dresses.htm\n",
      "134 /movies/?id=28days.htm\n",
      "135 /movies/?id=28dayslater.htm\n",
      "136 /movies/?id=28dayslatersecretcinema.htm\n",
      "137 /movies/?id=28hotelrooms.htm\n",
      "138 /movies/?id=28weekslater.htm\n",
      "139 /movies/?id=29thstreet.htm\n",
      "140 /movies/?id=2by4.htm\n",
      "141 /movies/?id=2ndanimationcelebration.htm\n",
      "142 /movies/?id=3.htm\n",
      "143 /movies/?id=3minutes10bullets.htm\n",
      "144 /movies/?id=3backyards.htm\n",
      "145 /movies/?id=threedaystokill.htm\n",
      "146 /movies/?id=3geezers.htm\n",
      "147 /movies/?id=3godfathers.htm\n",
      "148 /movies/?id=3hearts.htm\n",
      "149 /movies/?id=3idiots.htm\n",
      "150 /movies/?id=3needles.htm\n",
      "151 /movies/?id=3nightsinthedesert.htm\n",
      "152 /movies/?id=3ninjas.htm\n",
      "153 /movies/?id=3ninjaskickback.htm\n",
      "154 /movies/?id=3ninjasknuckleup.htm\n",
      "155 /movies/?id=3ninjas4.htm\n",
      "156 /movies/?id=3roomsofmelancholia.htm\n",
      "157 /movies/?id=3strikes.htm\n",
      "158 /movies/?id=3weeksinyerevan.htm\n",
      "159 /movies/?id=321frankie.htm\n",
      "160 /movies/?id=3iron.htm\n",
      "161 /movies/?id=30beats.htm\n",
      "162 /movies/?id=30daysofnight.htm\n",
      "163 /movies/?id=30minutesorless.htm\n",
      "164 /movies/?id=30yearstolife.htm\n",
      "165 /movies/?id=300.htm\n",
      "166 /movies/?id=300spartans.htm\n",
      "167 /movies/?id=3000milestograceland.htm\n",
      "168 /movies/?id=300sequel.htm\n",
      "169 /movies/?id=31.htm\n",
      "170 /movies/?id=33.htm\n",
      "171 /movies/?id=35andticking.htm\n",
      "172 /movies/?id=35shotsofrum.htm\n",
      "173 /movies/?id=35up.htm\n",
      "174 /movies/?id=36hours.htm\n",
      "175 /movies/?id=36saints.htm\n",
      "176 /movies/?id=360.htm\n",
      "177 /movies/?id=39poundsoflove.htm\n",
      "178 /movies/?id=39steps.htm\n",
      "179 /movies/?id=3:10toyuma57.htm\n",
      "180 /movies/?id=310toyuma.htm\n",
      "181 /movies/?id=3rdanimationcelebration.htm\n",
      "182 /movies/?id=4.htm\n",
      "183 /movies/?id=4littlegirls.htm\n",
      "184 /movies/?id=4months3weeks2days.htm\n",
      "185 /movies/?id=40daysand40nights.htm\n",
      "186 /movies/?id=40yearoldvirgin.htm\n",
      "187 /movies/?id=400blows.htm\n",
      "188 /movies/?id=42.htm\n",
      "189 /movies/?id=42up.htm\n",
      "190 /movies/?id=42ndstreet.htm\n",
      "191 /movies/?id=44inchchest.htm\n",
      "192 /movies/?id=45years.htm\n",
      "193 /movies/?id=45365.htm\n",
      "194 /movies/?id=47ronin.htm\n",
      "195 /movies/?id=48hrs.htm\n",
      "196 /movies/?id=49up.htm\n",
      "197 /movies/?id=49thparallel.htm\n",
      "198 /movies/?id=444lastdayonearth.htm\n",
      "199 /movies/?id=4thanimationcelebration.htm\n",
      "200 /movies/?id=4thtenor.htm\n",
      "201 /movies/?id=fivebrokencameras.htm\n",
      "202 /movies/?id=5daysofwar.htm\n",
      "203 /movies/?id=5flightsup.htm\n",
      "204 /movies/?id=5to7.htm\n",
      "205 /movies/?id=50firstdates.htm\n",
      "206 /movies/?id=50to1.htm\n",
      "207 /movies/?id=50waysofsayingfabulous.htm\n",
      "208 /movies/?id=50fifty.htm\n",
      "209 /movies/?id=51birchstreet.htm\n",
      "210 /movies/?id=52pickup.htm\n",
      "211 /movies/?id=52tuesdays.htm\n",
      "212 /movies/?id=54.htm\n",
      "213 /movies/?id=56up.htm\n",
      "214 /movies/?id=5thquarter.htm\n",
      "215 /movies/?id=5thwave.htm\n",
      "216 /movies/?id=5x2.htm\n",
      "217 /movies/?id=6monthrule.htm\n",
      "218 /movies/?id=shelter2011.htm\n",
      "219 /movies/?id=6years.htm\n",
      "220 /movies/?id=600millas.htm\n",
      "221 /movies/?id=6thday.htm\n",
      "222 /movies/?id=6thman.htm\n",
      "223 /movies/?id=7boxes.htm\n",
      "224 /movies/?id=7chinesebrothers.htm\n",
      "225 /movies/?id=7dias.htm\n",
      "226 /movies/?id=7khoonmaaf.htm\n",
      "227 /movies/?id=7minutes.htm\n",
      "228 /movies/?id=71.htm\n",
      "229 /movies/?id=71intothefire.htm\n",
      "230 /movies/?id=7500.htm\n",
      "231 /movies/?id=7thstreet.htm\n",
      "232 /movies/?id=81299.htm\n",
      "233 /movies/?id=812women.htm\n",
      "234 /movies/?id=8filmstodiefor2015.htm\n",
      "235 /movies/?id=8headsinaduffelbag.htm\n",
      "236 /movies/?id=8mile.htm\n",
      "237 /movies/?id=8millionwaystodie.htm\n",
      "238 /movies/?id=8seconds.htm\n",
      "239 /movies/?id=8women.htm\n",
      "240 /movies/?id=800bullets.htm\n",
      "241 /movies/?id=84charingcrossroad.htm\n",
      "242 /movies/?id=88minutes.htm\n",
      "243 /movies/?id=8mormonproposition.htm\n",
      "244 /movies/?id=8mm.htm\n",
      "245 /movies/?id=9.htm\n",
      "246 /movies/?id=9andonehalfweeks.htm\n",
      "247 /movies/?id=9songs.htm\n",
      "248 /movies/?id=9to5.htm\n",
      "249 /movies/?id=90minutesinheaven.htm\n",
      "250 /movies/?id=95milestogo.htm\n",
      "251 /movies/?id=976-evil.htm\n",
      "252 /movies/?id=99homes.htm\n",
      "253 /movies/?id=99percent.htm\n",
      "254 /movies/?id=rec2.htm\n",
      "255 /movies/?id=ateam.htm\n",
      "256 /movies/?id=acod.htm\n",
      "257 /movies/?id=ai.htm\n",
      "258 /movies/?id=aaa.htm\n",
      "259 /movies/?id=aajanachle.htm\n",
      "260 /movies/?id=aarakshan.htm\n",
      "261 /movies/?id=aashayein.htm\n",
      "262 /movies/?id=aatsinki.htm\n",
      "263 /movies/?id=abandon.htm\n",
      "264 /movies/?id=abandoned.htm\n",
      "265 /movies/?id=abcafrica.htm\n",
      "266 /movies/?id=abcsofdeath.htm\n",
      "267 /movies/?id=abcd.htm\n",
      "268 /movies/?id=abcd2013.htm\n",
      "269 /movies/?id=abcd2.htm\n",
      "270 /movies/?id=abcsofdeath2.htm\n",
      "271 /movies/?id=abduction11.htm\n",
      "272 /movies/?id=abduction.htm\n",
      "273 /movies/?id=abel.htm\n",
      "274 /movies/?id=aberdeen.htm\n",
      "275 /movies/?id=abominable.htm\n",
      "276 /movies/?id=abouna.htm\n",
      "277 /movies/?id=aboutaboy.htm\n",
      "278 /movies/?id=aboutadam.htm\n",
      "279 /movies/?id=aboutalex.htm\n",
      "280 /movies/?id=aboutcherry.htm\n",
      "281 /movies/?id=aboutelly.htm\n",
      "282 /movies/?id=aboutfifty.htm\n",
      "283 /movies/?id=aboutlastnight14.htm\n",
      "284 /movies/?id=aboutlastnight.htm\n",
      "285 /movies/?id=aboutray.htm\n",
      "286 /movies/?id=aboutschmidt.htm\n",
      "287 /movies/?id=abouttime.htm\n",
      "288 /movies/?id=aboveandbelow.htm\n",
      "289 /movies/?id=aboveandbeyond.htm\n",
      "290 /movies/?id=abovethelaw.htm\n",
      "291 /movies/?id=abovetherim.htm\n",
      "292 /movies/?id=abrahamlincolnvampirehunter.htm\n",
      "293 /movies/?id=absence.htm\n",
      "294 /movies/?id=absenceofmalice.htm\n",
      "295 /movies/?id=absolutebeginners.htm\n",
      "296 /movies/?id=absolutepower.htm\n",
      "297 /movies/?id=absolutewilson.htm\n",
      "298 /movies/?id=absolutelyanything.htm\n",
      "299 /movies/?id=absolutelyfabulousthemovie.htm\n",
      "300 /movies/?id=absurdistan.htm\n",
      "301 /movies/?id=abuseofweakness.htm\n",
      "302 /movies/?id=abyss.htm\n",
      "303 /movies/?id=abyss93.htm\n",
      "304 /movies/?id=accepted.htm\n",
      "305 /movies/?id=accident.htm\n",
      "306 /movies/?id=accidentalhusband.htm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/Users/ausubo/anaconda/envs/py35/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.6 and older\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-b6c180f44e6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#dict_1 = scrape_movie_data(all_movies)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdict_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovie_scraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_movies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-b9029fb4e1cc>\u001b[0m in \u001b[0;36mmovie_scraper\u001b[0;34m(all_movies)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"http://www.boxofficemojo.com/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmovie\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ausubo/anaconda/envs/py35/lib/python3.5/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ausubo/anaconda/envs/py35/lib/python3.5/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ausubo/anaconda/envs/py35/lib/python3.5/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    473\u001b[0m         }\n\u001b[1;32m    474\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ausubo/anaconda/envs/py35/lib/python3.5/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ausubo/anaconda/envs/py35/lib/python3.5/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    401\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m                 )\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ausubo/anaconda/envs/py35/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, **response_kw)\u001b[0m\n\u001b[1;32m    576\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ausubo/anaconda/envs/py35/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    385\u001b[0m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.6 and older\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ausubo/anaconda/envs/py35/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1198\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ausubo/anaconda/envs/py35/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ausubo/anaconda/envs/py35/lib/python3.5/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ausubo/anaconda/envs/py35/lib/python3.5/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#dict_1 = scrape_movie_data(all_movies)\n",
    "dict_1 = movie_scraper(all_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns = ['movie', 'genre','release date', 'distributor', 'runtime', 'rating', 'budget', 'domestic gross', 'actors', '1st weekend gross', 'widest release', 'producers', 'directors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle('movies_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['title'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.index = range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# /movies/?id=punchline.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle('movies_1_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_2 = movie_scraper(all_movies[11924:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(dict_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df2.transpose()\n",
    "df2.columns = ['movie', 'genre','release date', 'distributor', 'runtime', 'rating', 'budget', 'domestic gross', 'actors', '1st weekend gross', 'widest release', 'producers', 'directors']\n",
    "df2['title'] = df2.index\n",
    "df2.index = range(len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.to_pickle('movies_2.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_genres(soup):\n",
    "    \"\"\" returns all genres from specific movie page at boxofficemojo.com\"\"\"\n",
    "    genres_list = []\n",
    "    try:\n",
    "        genres = soup.find(id=\"body\").find(text=re.compile(\"Genres\"))\n",
    "        genres = genres.findParent().findNextSibling().find_all('tr')\n",
    "        genre_count = 0\n",
    "        for genre in genres:\n",
    "            if genre_count > 0:\n",
    "                genres_list.append(genre.td.font.a.text)\n",
    "            genre_count += 1\n",
    "    except LookupError:\n",
    "        try:\n",
    "            genres = soup.find(id=\"body\").find(text=re.compile(\"Genre\"))\n",
    "            genres = genres.findNextSibling().text\n",
    "            genres_list.append(genres)\n",
    "        except:\n",
    "            genres_list.append(\"N/A\")\n",
    "    return genres_list\n",
    "\n",
    "\n",
    "def get_title(soup):\n",
    "    \"\"\"returns title from specific movie page at boxofficemojo.com\"\"\"\n",
    "    try:\n",
    "        title = soup.find(\"title\").text.rsplit('(', 1)[0].strip()\n",
    "    except LookupError:\n",
    "        title = \"N/A\"\n",
    "    return title\n",
    "\n",
    "\n",
    "def get_release_date(soup):\n",
    "    \"\"\"returns datetime value of release date from specific movie\n",
    "    page at boxofficemojo.com\n",
    "    \"\"\"\n",
    "    try:\n",
    "        date = soup.find(id=\"body\").find(text=re.compile(\"Release Date\"))\n",
    "        date = date.findNextSibling().text\n",
    "        date = datetime.strptime(date, \"%B %d, %Y\")\n",
    "        return date\n",
    "    except LookupError:\n",
    "        return \"N/A\"\n",
    "\n",
    "\n",
    "def get_distributor(soup):\n",
    "    \"\"\"returns movie distributor from specific movie page at boxofficemojo.com\"\"\"\n",
    "    try:\n",
    "        distributor = soup.find(id=\"body\").find(text=re.compile(\"Distributor\"))\n",
    "        distributor = distributor.findNextSibling().text\n",
    "        return distributor\n",
    "    except LookupError:\n",
    "        return \"N/A\"\n",
    "\n",
    "\n",
    "def get_rating(soup):\n",
    "    \"\"\"returns MPAA Rating from specific movie page at boxofficemojo.com\"\"\"\n",
    "    try:\n",
    "        rating = soup.find(id=\"body\").find(text=re.compile(\"MPAA Rating\"))\n",
    "        rating = rating.findNextSibling().text\n",
    "        return rating\n",
    "    except LookupError:\n",
    "        return \"N/A\"\n",
    "\n",
    "\n",
    "def get_runtime(soup):\n",
    "    \"\"\"returns integer value of runtime from specific movie page at boxofficemojo.com\"\"\"\n",
    "    try:\n",
    "        runtime = soup.find(id=\"body\").find(text=re.compile(\"Runtime\"))\n",
    "        runtime = runtime.findNextSibling().text\n",
    "        time_splits = runtime.split(\"hrs.\")\n",
    "        try:\n",
    "            hrs = int(time_splits[0]) * 60\n",
    "        except LookupError:\n",
    "            hrs = 0\n",
    "        mins = int(time_splits[1].split(\" min.\")[0].strip())\n",
    "        total = hrs + mins\n",
    "        return total\n",
    "    except LookupError:\n",
    "        return \"N/A\"\n",
    "\n",
    "\n",
    "def get_budget(soup):\n",
    "    \"\"\"returns movie budget from specific movie page at boxofficemojo.com\"\"\"\n",
    "    try:\n",
    "        budget = soup.find(id=\"body\").find(text=re.compile(\"Production Budget\"))\n",
    "        budget = budget.findNextSibling().text\n",
    "        if budget != \"N/A\":\n",
    "            budget = int(budget.split(\"million\")[0].split(\"$\")[1].strip()) * 1000000\n",
    "        return budget\n",
    "    except LookupError:\n",
    "        return \"N/A\"\n",
    "\n",
    "\n",
    "def get_domestic_gross(soup):\n",
    "    \"\"\"returns integer value of domestic gross from specific movie page at boxofficemojo.com\"\"\"\n",
    "    try:\n",
    "        gross = soup.find(id=\"body\").find(text=re.compile(\"Domestic Total Gross: \"))\n",
    "        gross = gross.findNextSibling().text\n",
    "        gross = int(gross.replace(\"$\", \"\").replace(\",\", \"\"))\n",
    "        return gross\n",
    "    except LookupError:\n",
    "        try:\n",
    "            gross = soup.find(id=\"body\").find(tex=re.compile(\"Domestic:\"))\n",
    "            gross = gross.findParent().findNextSibling().text\n",
    "            return gross\n",
    "        except:\n",
    "            return \"N/A\"\n",
    "        \n",
    "        \n",
    "def get_movie_value_next(soup, field_name):\n",
    "    '''Grab a value from boxofficemojo HTML\n",
    "    \n",
    "    Takes a string attribute of a movie on the page and\n",
    "    returns the string in the next sibling object\n",
    "    (the value for that attribute)\n",
    "    or None if nothing is found.\n",
    "    '''\n",
    "    obj = soup.find(text=re.compile(field_name))\n",
    "    \n",
    "    if obj:\n",
    "        return obj.next.text\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_actors(soup):\n",
    "    actor = get_movie_value_next(soup,'Actor')\n",
    "    v = re.sub('([a-z()])([A-Z])', '\\g<1>, \\g<2>', actor)\n",
    "    actors = re.sub('[(*\\']','', v)\n",
    "    actors = actors.split(\",\")\n",
    "    return actors\n",
    "\n",
    "\n",
    "def money_to_int(moneystring):\n",
    "    moneystring = moneystring.replace('$', '').replace(',', '')\n",
    "    return int(moneystring)\n",
    "\n",
    "def get_opening_weekend(soup):\n",
    "    opening_weekend_gross = get_movie_value_next(soup,'Opening Weekend')\n",
    "    opening_weekend_gross = money_to_int(opening_weekend_gross)\n",
    "    return opening_weekend_gross\n",
    "    \n",
    "    \n",
    "def scrape_movie_data(movie_list, start=0, end=20000):\n",
    "    \"\"\"returns dictionary of movies and relevant data from boxofficemojo.com:\n",
    "    genres(as a list), release date, distributor, runtime, MPAA rating,\n",
    "    budget, gross domestic revenue\n",
    "    \"\"\"\n",
    "    movie_data_list = {}\n",
    "    counter = 0\n",
    "    for movie in movie_list:\n",
    "        try:\n",
    "            if start < counter < end and counter < len(movie_list):\n",
    "                url = \"http://www.boxofficemojo.com/\" + movie\n",
    "                \n",
    "                response = requests.get(url)\n",
    "                time.sleep(0.1)\n",
    "                page = response.text\n",
    "                soup = BeautifulSoup(page, \"lxml\")\n",
    "                print(movie)\n",
    "                movie_data_list[get_title(soup)] = [get_genres(soup), get_release_date(soup), \n",
    "                                                    get_distributor(soup), get_runtime(soup), \n",
    "                                                    get_rating(soup), get_budget(soup), \n",
    "                                                    get_domestic_gross(soup), get_actors(soup), \n",
    "                                                    get_opening_weekend(soup)]\n",
    "                \n",
    "            counter += 1\n",
    "        except: #(Exception, e):\n",
    "            pass\n",
    "\n",
    "    return movie_data_list\n",
    "\n",
    "\n",
    "#def main():\n",
    "#    pass\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_data_subset = scrape_movie_data(all_movies_subset, start=0, end=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_data_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(movie_data_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_list_A = []\n",
    "url = 'http://www.boxofficemojo.com/movies/alphabetical.htm?letter=A&page=1'\n",
    "response = requests.get(url)\n",
    "page = response.text\n",
    "soup = BeautifulSoup(page, 'lxml')\n",
    "rows = soup.find(id = 'body').find('table').find('table').find_all('table')[1].find_all(\"tr\")\n",
    "if len(rows) > 1:\n",
    "    counter = 1\n",
    "    for row in rows:\n",
    "    # skip index row\n",
    "        if counter > 1:\n",
    "            link = row.td.font.a['href']\n",
    "            # don't add duplicates\n",
    "            if link not in movies_list:\n",
    "                movies_list_A.append(link)\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def movie_actors(soup):\n",
    "    try:\n",
    "        actor = get_movie_value_next_next(soup,'Actor')\n",
    "        v = re.sub('([a-z()])([A-Z])', '\\g<1>, \\g<2>', actor)\n",
    "        if \"*\" in v:\n",
    "            actors = v.split('*')\n",
    "        else:\n",
    "            actors = re.sub('[(*\\']','', v)\n",
    "            actors = actors.split(\",\")\n",
    "        #if \"*\" in actors:\n",
    "        #    actors =  actors.split('*')\n",
    "\n",
    "    except TypeError:\n",
    "        actors = float('NaN')\n",
    "    return actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_movie_value_next_next(soup, field_name):\n",
    "    '''Grab a value from boxofficemojo HTML\n",
    "    \n",
    "    Takes a string attribute of a movie on the page and\n",
    "    returns the string in the next sibling object\n",
    "    (the value for that attribute)\n",
    "    or None if nothing is found.\n",
    "    '''\n",
    "    obj = soup.find(text=re.compile(field_name))\n",
    "    \n",
    "    if obj:\n",
    "        return obj.next.next.text\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_movie_value_next(soup, field_name):\n",
    "    '''Grab a value from boxofficemojo HTML\n",
    "    \n",
    "    Takes a string attribute of a movie on the page and\n",
    "    returns the string in the next sibling object\n",
    "    (the value for that attribute)\n",
    "    or None if nothing is found.\n",
    "    '''\n",
    "    obj = soup.find(text=re.compile(field_name))\n",
    "    if not obj: \n",
    "        return None\n",
    "    # this works for most of the values\n",
    "    next_sibling = obj.findNextSibling()\n",
    "    if next_sibling:\n",
    "        return next_sibling.text # RETURN TEXT OF NEXT SIBLING\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def release_date(soup):\n",
    "    try:\n",
    "        raw_release_date = get_movie_value(soup,'Release Date')\n",
    "        if raw_release_date != 'TBD' and raw_release_date != 'N/A' and raw_release_date.split()[0] != 'Spring' and raw_release_date.split()[0] != 'Summer' and raw_release_date.split()[0] != 'Fall' and raw_release_date.split()[0] != 'Winter' :\n",
    "            release_date = to_date(raw_release_date)\n",
    "        else:\n",
    "            release_date = float('NaN')\n",
    "    except AttributeError:\n",
    "        release_date = float('NaN')\n",
    "    return release_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_actors(soup):\n",
    "    actor = get_movie_value_next(soup,'Actor')\n",
    "    v = re.sub('([a-z()])([A-Z])', '\\g<1>, \\g<2>', actor)\n",
    "    v = v.replace('(, Voice)','')\n",
    "    actors = re.sub('[(*\\']','', v)\n",
    "    actors = actors.split(\",\")\n",
    "    return actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def movie_actors(soup):\n",
    "    try:\n",
    "        actor = get_movie_value_next_next(soup,'Actor')\n",
    "        v = re.sub('([a-z()])([A-Z])', '\\g<1>, \\g<2>', actor)\n",
    "        if \"*\" in v:\n",
    "            actors = v.split('*')\n",
    "        else:\n",
    "            actors = re.sub('[(*\\']','', v)\n",
    "            actors = actors.split(\",\")\n",
    "        #if \"*\" in actors:\n",
    "        #    actors =  actors.split('*')\n",
    "\n",
    "    except TypeError:\n",
    "        actors = float('NaN')\n",
    "    return actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#url = 'http://www.boxofficemojo.com/movies/?id=disney2016.htm'\n",
    "url = 'http://www.boxofficemojo.com/movies/?id=ghostbusters2016.htm'\n",
    "response = requests.get(url)\n",
    "page = response.text\n",
    "soup = BeautifulSoup(page, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sigourney Weaver* (Cameo)Melissa McCarthyKristen WiigKate McKinnonLeslie JonesCharles DanceMichael K. WilliamsChris Hemsworth'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_movie_value_next_next(soup, 'Actor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor = get_movie_value_next_next(soup,'Actor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sigourney Weaver* (Cameo)Melissa McCarthyKristen WiigKate McKinnonLeslie JonesCharles DanceMichael K. WilliamsChris Hemsworth'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def movie_actors(soup): # still doesn't deal well with McPeople\n",
    "    try:\n",
    "        actor = get_movie_value_next_next(soup,'Actor') # try get_movie_value_next if it doesnt work \n",
    "        actor = actor.replace('*','')\n",
    "        v = re.sub('([a-z()])([A-Z])', '\\g<1>,\\g<2>', actor)\n",
    "        v = v.replace(' (,Voice)','')\n",
    "        v = v.replace(' (,Cameo)','')\n",
    "        actors = re.sub('[(*\\']','', v)\n",
    "        actors = actors.split(',')\n",
    "        #if \"*\" in v:\n",
    "        #    actors = v.split('*')\n",
    "        #else:\n",
    "        #    actors = re.sub('[(*\\']','', v)\n",
    "        #    actors = actors.split(\",\")\n",
    "\n",
    "    except TypeError:\n",
    "        actors = float('NaN')\n",
    "    return actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# startswith()\n",
    "# Mc, De, van, Mac, Du, Le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sigourney Weaver', 'Melissa Mc', 'Carthy', 'Kristen Wiig', 'Kate Mc', 'Kinnon', 'Leslie Jones', 'Charles Dance', 'Michael K. Williams', 'Chris Hemsworth']\n"
     ]
    }
   ],
   "source": [
    "print (movie_actors(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor = get_movie_value_next_next(soup, 'Actor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor = actor.replace('*','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sigourney Weaver (Cameo)Melissa McCarthyKristen WiigKate McKinnonLeslie JonesCharles DanceMichael K. WilliamsChris Hemsworth'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = actor.replace('(Cameo)','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = re.sub('([a-z()])([A-Z])', '\\g<1>, \\g<2>', actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sigourney Weaver (,Cameo),Melissa Mc,Carthy,Kristen Wiig,Kate Mc,Kinnon,Leslie Jones,Charles Dance,Michael K. Williams,Chris Hemsworth'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
